{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uber's Ludwig: Datatype Agnostic Toolbox Built on top of TensorFlow\n",
    "\n",
    "### by Scott Jones\n",
    "### August 23, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](ludwig_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- easy to use (basically no coding)\n",
    "\n",
    "- visualization of model performance (including model comparisons)\n",
    "\n",
    "- flexible to many different model parameters\n",
    "\n",
    "- generally applicable to wide range of use cases\n",
    "\n",
    "- regularly updated (new BERT functionality)\n",
    "\n",
    "- can load data from AWS, GCP, Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "- github.com/uber/ludwig\n",
    "- uber.github.io\n",
    "    - Getting Started\n",
    "    - Examples\n",
    "    - User Guide\n",
    "    - API\n",
    "- https://towardsdatascience.com/introducing-ubers-ludwig-5bd275a73eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](ludwig_example_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*ludwig train --data_csv reuters-allcats.csv --model_definition \"{input_features: [{name: text, type: text, encoder: parallel_cnn, level: word}], output_features: [{name: class, type: category}]}\"*\n",
    "\n",
    "![title](terminal_training_run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*ludwig predict --data_csv reuters-allcats.csv --model_path results/experiment_run_0/model/*\n",
    "\n",
    "![title](predict_file_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Or, can combine training and test into a single command:\n",
    "\n",
    "*ludwig experiment --data_csv reuters-allcats.csv --model_definition \"{input_features: [{name: text, type: text, encoder: parallel_cnn, level: word}], output_features: [{name: class, type: category}]}\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Can also put the model definition into a YAML file:\n",
    "\n",
    "input_features:  \n",
    "    -  \n",
    "        name: text  \n",
    "        type: text  \n",
    "        level: word  \n",
    "        encoder: parallel_cnn\n",
    "\n",
    "output_features:  \n",
    "    -  \n",
    "        name: class  \n",
    "        type: category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "*ludwig visualize --visualization learning_curves --training_statistics path/to/training_statistics.json*\n",
    "\n",
    "![title](accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python API\n",
    "\n",
    "*!apt-get install libgmp3-dev*  \n",
    "*!pip install ludwig*\n",
    "\n",
    "### Train a model\n",
    "\n",
    "*model_definition = {...}*  \n",
    "*ludwig_model = LudwigModel(model_definition)*  \n",
    "*train_stats = ludwig_model.train(data_csv=csv_file_path)*\n",
    "\n",
    "### load a dataframe\n",
    "\n",
    "*train_stats = ludwig_model.train(data_df=dataframe)*\n",
    "\n",
    "### load a previously trained model\n",
    "\n",
    "*ludwig_model = LudwigModel.load(model_dir)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### predict\n",
    "\n",
    "*predictions = ludwig_model.predict(data_csv=csv_file_path) # dataframe also valid again*\n",
    "\n",
    "### test\n",
    "\n",
    "*predictions, test_stats = ludwig_model.test(data_csv=csv_file_path) # data_df=dataframe*\n",
    "\n",
    "### release resources\n",
    "\n",
    "*model.close()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Comparisons\n",
    "\n",
    "*compare_classifiers_performance_from_pred*\n",
    "\n",
    "![title](model_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*compare_classifiers_multiclass_multimetric*\n",
    "\n",
    "![title](multiclass_performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "![title](confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key advantage of Ludwig is the data-type specific encoders and decoders (adaptibility)\n",
    "\n",
    "- preprocessing methods specific to your data\n",
    "\n",
    "### For text data: \n",
    "\n",
    "- handled similar to sequence data but includes SpaCy based methods\n",
    "    - tokenizer\n",
    "    - stopword removal\n",
    "    - punctuation, number filter\n",
    "    - lemmatization\n",
    "- lowercase data, fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NLP Applications\n",
    "\n",
    "- Text classification\n",
    "- Natural Language Understanding\n",
    "- NER tagging\n",
    "- Translation\n",
    "- Chatbot modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208012</th>\n",
       "      <td>B007SH90RM</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was a good one, let's start by saying tha...</td>\n",
       "      <td>05 13, 2014</td>\n",
       "      <td>A2GU8WAUL1GREZ</td>\n",
       "      <td>Veritas Vincit \"Bill\"</td>\n",
       "      <td>Deep Mystery and Masterful Storytelling</td>\n",
       "      <td>1399939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590910</th>\n",
       "      <td>B00E123W58</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I was gifted my copy of RUNE II in exchange fo...</td>\n",
       "      <td>07 23, 2013</td>\n",
       "      <td>A1RUT4WFFKVI1I</td>\n",
       "      <td>Anne Nelson</td>\n",
       "      <td>What a explosion as it hit my kindle!!!!</td>\n",
       "      <td>1374537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563433</th>\n",
       "      <td>B00DKB3LKM</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I really liked this book. Another great book i...</td>\n",
       "      <td>06 26, 2013</td>\n",
       "      <td>A30GJ3BNSILI9D</td>\n",
       "      <td>Bill McBride</td>\n",
       "      <td>A fact fills story</td>\n",
       "      <td>1372204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375492</th>\n",
       "      <td>B00AM0WQD2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great information for creating gifts! I have m...</td>\n",
       "      <td>12 13, 2012</td>\n",
       "      <td>A3KBGY56U6MPA3</td>\n",
       "      <td>this is great</td>\n",
       "      <td>Definitely Recommended!</td>\n",
       "      <td>1355356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293305</th>\n",
       "      <td>B0094B6QQ8</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Very short story...not credible at all...and j...</td>\n",
       "      <td>09 14, 2013</td>\n",
       "      <td>A1JWFH1A4XT5PU</td>\n",
       "      <td>Diana Galan</td>\n",
       "      <td>Bah</td>\n",
       "      <td>1379116800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin helpful  overall  \\\n",
       "208012  B007SH90RM  [0, 0]      5.0   \n",
       "590910  B00E123W58  [0, 0]      5.0   \n",
       "563433  B00DKB3LKM  [0, 0]      5.0   \n",
       "375492  B00AM0WQD2  [1, 1]      5.0   \n",
       "293305  B0094B6QQ8  [0, 0]      2.0   \n",
       "\n",
       "                                               reviewText   reviewTime  \\\n",
       "208012  This was a good one, let's start by saying tha...  05 13, 2014   \n",
       "590910  I was gifted my copy of RUNE II in exchange fo...  07 23, 2013   \n",
       "563433  I really liked this book. Another great book i...  06 26, 2013   \n",
       "375492  Great information for creating gifts! I have m...  12 13, 2012   \n",
       "293305  Very short story...not credible at all...and j...  09 14, 2013   \n",
       "\n",
       "            reviewerID           reviewerName  \\\n",
       "208012  A2GU8WAUL1GREZ  Veritas Vincit \"Bill\"   \n",
       "590910  A1RUT4WFFKVI1I            Anne Nelson   \n",
       "563433  A30GJ3BNSILI9D           Bill McBride   \n",
       "375492  A3KBGY56U6MPA3          this is great   \n",
       "293305  A1JWFH1A4XT5PU            Diana Galan   \n",
       "\n",
       "                                         summary  unixReviewTime  \n",
       "208012   Deep Mystery and Masterful Storytelling      1399939200  \n",
       "590910  What a explosion as it hit my kindle!!!!      1374537600  \n",
       "563433                        A fact fills story      1372204800  \n",
       "375492                   Definitely Recommended!      1355356800  \n",
       "293305                                       Bah      1379116800  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "#!pip install bert-tensorflow\n",
    "\n",
    "path=\"/Users/sjones/Google Drive/Kindle_rating_predict\"\n",
    "\n",
    "reviews = []\n",
    "file = \"/Users/sjones/Google Drive/Kindle_rating_predict/reviews_Kindle_Store_5.json\"\n",
    "for line in open(file, 'r'):\n",
    "    reviews.append(json.loads(line))\n",
    "    \n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "train, test = train_test_split(reviews_df, test_size=0.15, random_state=42, shuffle=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_sm = pd.concat([train['overall'], train['reviewText']], axis=1)\n",
    "test_sm = pd.concat([test['overall'], test['reviewText']], axis=1)\n",
    "\n",
    "# Get rid of reviews with no text\n",
    "noDataTr = train_sm[train_sm['reviewText'] == \"\"].index\n",
    "train_sm.drop(noDataTr, inplace=True)\n",
    "noDataTe = test_sm[test_sm['reviewText'] == \"\"].index\n",
    "test_sm.drop(noDataTe, inplace=True)\n",
    "\n",
    "# Restrict our data set \n",
    "#train_sm = train_sm.sample(frac=0.3, random_state=42)\n",
    "train_sm = train_sm.sample(n=1000, random_state=42)\n",
    "test_sm = test_sm.sample(n=200, random_state=42)\n",
    "\n",
    "my_dict = {1.0: \"one star\", 2.0: \"two stars\", 3.0: \"three stars\", 4.0: \"four stars\", 5.0: \"five stars\"}\n",
    "train_sm = train_sm.replace({\"overall\": my_dict})\n",
    "test_sm = test_sm.replace({\"overall\": my_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:137: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:141: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:144: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/inputs.py:60: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/inputs.py:60: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/features/category_feature.py:451: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/modules/loss_modules.py:291: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/modules/optimization_modules.py:84: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:211: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:216: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/ludwig/models/model.py:422: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "\n",
      "Received SIGINT, will finish this epoch and then conclude the training\n",
      "Send another SIGINT to immediately interrupt the process\n"
     ]
    }
   ],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "\n",
    "# train a model\n",
    "model_definition = {'input_features': [{'name': 'reviewText', 'type': 'text', 'level': 'word', 'encoder': 'parallel_cnn', \n",
    "                                      'do_lower_case': 'True', 'preprocessing': {'word_tokenizer': 'english_tokenize_filter'}}], 'output_features': [{'name': 'overall', 'type': 'category'}]}\n",
    "\n",
    "#print(model_definition)\n",
    "\n",
    "model = LudwigModel(model_definition)\n",
    "train_stats = model.train(train_sm)\n",
    "\n",
    "# or load a model\n",
    "#model = LudwigModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# obtain predictions\n",
    "predictions = model.predict(test_sm)\n",
    "\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embeddings\n",
    "\n",
    "- allow shared representations across disparate data sets (transfer learning)\n",
    "- lower dimensional representations of word vectors that maintain context\n",
    "- also: language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](transfer_learning_schematic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Google's BERT (Bidirectional Encoder Representations from Transformers) also now available in Ludwig:\n",
    "\n",
    "model_definition = {'input_features': [{'name': 'reviewText', 'type': 'text', 'encoder': 'bert', 'config_path': '/content/drive/My Drive/Kindle_rating_predict/wwm_uncased_L-24_H-1024_A-16/bert_config.json', \n",
    "                                      'checkpoint_path': '/content/drive/My Drive/Kindle_rating_predict/wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt', 'do_lower_case': 'True',\n",
    "                                     'preprocessing': {'word_tokenizer': 'bert', 'word_vocab_file': '/content/drive/My Drive/Kindle_rating_predict/wwm_uncased_L-24_H-1024_A-16/vocab.txt', 'padding_symbol': '[PAD]',\n",
    "                                                    'unknown_symbol': '[UNK]'}, 'reduce_output': 'True'}], 'output_features': [{'name': 'overall', 'type': 'category'}]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using BERT in Ludwig\n",
    "\n",
    "- BERT tokenizer must be used \n",
    "- maps each integer in sequence to its embedding (encoder of Transformer)\n",
    "- load downloaded BERT weights, hyperparameters and vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
